{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcUgcSPDKgqg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUhQfQscKj3c",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, callbacks, regularizers\n",
        "from tensorflow.keras.applications import DenseNet201\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import pandas as pd\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "\n",
        "# Set paths to your dataset directories\n",
        "dataset_dir = r'/content/drive/MyDrive/Thesis_paper_1_Driver_Fatic_topic_8_type_clasification/training_set'\n",
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "test_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "# Helper function to handle read-only files during deletion\n",
        "def handle_remove_readonly(func, path, exc):\n",
        "    import stat\n",
        "    os.chmod(path, stat.S_IWRITE)\n",
        "    func(path)\n",
        "\n",
        "# Helper function to retry directory deletion if a PermissionError occurs\n",
        "def remove_dir_with_retry(path):\n",
        "    retries = 3\n",
        "    for i in range(retries):\n",
        "        try:\n",
        "            shutil.rmtree(path, onerror=handle_remove_readonly)\n",
        "            print(f\"Successfully deleted: {path}\")\n",
        "            break\n",
        "        except PermissionError as e:\n",
        "            print(f\"PermissionError: {e}. Retrying in 2 seconds... ({i+1}/{retries})\")\n",
        "            time.sleep(2)\n",
        "    else:\n",
        "        print(f\"Could not delete {path} after {retries} retries.\")\n",
        "\n",
        "# Clear old directories if they exist\n",
        "for folder in [train_dir, test_dir]:\n",
        "    if os.path.exists(folder):\n",
        "        remove_dir_with_retry(folder)\n",
        "\n",
        "# Helper function to split data into train and test\n",
        "def split_data(data_dir, train_dir, test_dir, train_ratio=0.8):\n",
        "    classes = [cls for cls in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, cls))]\n",
        "\n",
        "    for cls in classes:\n",
        "        cls_dir = os.path.join(data_dir, cls)\n",
        "        images = os.listdir(cls_dir)\n",
        "\n",
        "        # Shuffle and split images\n",
        "        np.random.shuffle(images)\n",
        "        train_count = int(len(images) * train_ratio)\n",
        "\n",
        "        train_images = images[:train_count]\n",
        "        test_images = images[train_count:]\n",
        "\n",
        "        # Copy images to new directories\n",
        "        for subset, subset_images in zip([train_dir, test_dir], [train_images, test_images]):\n",
        "            subset_cls_dir = os.path.join(subset, cls)\n",
        "            os.makedirs(subset_cls_dir, exist_ok=True)\n",
        "            for img in subset_images:\n",
        "                shutil.copy(os.path.join(cls_dir, img), os.path.join(subset_cls_dir, img))\n",
        "\n",
        "# Perform data splitting\n",
        "split_data(dataset_dir, train_dir, test_dir)\n",
        "\n",
        "# Create instances of ImageDataGenerator for training and testing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create generators for training and testing\n",
        "batch_size = 64\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Use DenseNet201 as the base model\n",
        "base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False  # Freeze the pre-trained layers\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(7, activation='softmax')  # Adjust for your number of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "model_checkpoint = callbacks.ModelCheckpoint('best_model_densenet201.keras', save_best_only=True, monitor='val_loss')\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=35,\n",
        "    callbacks=[model_checkpoint, reduce_lr, early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_accuracy:.2f}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze training history\n",
        "history_df = pd.DataFrame({\n",
        "    \"Epoch\": range(1, len(history.history['accuracy']) + 1),\n",
        "    \"Train Accuracy\": history.history['accuracy'],\n",
        "    \"Validation Accuracy\": history.history['val_accuracy'],\n",
        "    \"Train Loss\": history.history['loss'],\n",
        "    \"Validation Loss\": history.history['val_loss']\n",
        "})\n",
        "print(\"\\nTrain and Validation Accuracy and Loss by Epoch:\")\n",
        "print(history_df)\n",
        "\n",
        "# Generate classification report and confusion matrix\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "classification_report_dict = classification_report(true_labels, predicted_labels, target_names=class_labels, output_dict=True)\n",
        "classification_df = pd.DataFrame(classification_report_dict).transpose()\n",
        "print(\"\\nClass-wise Accuracy and Loss:\")\n",
        "print(classification_df)\n",
        "\n",
        "# Plot training results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Final Test Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.axhline(y=test_loss, color='r', linestyle='--', label='Final Test Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix\n",
        "test_generator.reset()\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "class_labels = list(test_generator.class_indices.keys())\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d', xticks_rotation=45)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FVOFpGcjd9n1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}